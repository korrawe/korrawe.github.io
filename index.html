<!Doctype html>
<html lang="en">
    <head>
        <title>Korrawe Karunratanakul</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Korrawe Karunratanakul">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" type="text/css" href="style.css?cache=7733391418498779688">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <link rel="icon" type="image/png" href="figures/favicon.png"/>
    </head>
    <body>
        <div class="section">
            <div class="title">
                <span> Korrawe Karunratanakul </span>
            </div>
            <div class="row">
                <div class="image" id="profile-photo">
                    <!-- <a href=https://www.google.com/search?q=%CE%BA%CE%BF%CF%85%CF%86%CE%BF%CE%BD%CE%AE%CF%83%CE%B9%CE%B1&tbm=isch&ved=2ahUKEwj7jrmr-4rpAhVEt6QKHdQLBBsQ2-cCegQIABAA&oq=%CE%BA%CE%BF%CF%85%CF%86%CE%BF%CE%BD%CE%AE%CF%83%CE%B9%CE%B1&gs_lcp=CgNpbWcQA1AAWABgzL0BaABwAHgAgAEAiAEAkgEAmAEAqgELZ3dzLXdpei1pbWc&sclient=img&ei=SAyoXvvKIsTukgXUl5DYAQ&bih=949&biw=1920> -->
                    <img alt="Profile photo" src="figures/me-small.jpg" />
                    </a>
                </div>
                <div class="content">
                    <p>
                        I am a PhD student at
                        <a href=https://ethz.ch/en.html/>
                        ETH Zurich </a>.
                    </p>
                    <p style="text-align:center">
                        <span class="icon">
                            <a href=mailto:korrawe.karunratanakul@inf.ethz.ch>
                                <i class="fa fa-envelope-square fa-2x" aria-hidden="true"></i>
                            </a>
                        </span>
                        <!-- <span class="icon">
                            <a href=https://scholar.google.de/citations?user=zxFlR6sAAAAJ&hl=en&oi=ao>
                            <i class="ai ai-google-scholar-square ai-2x"></i>
                            </a> 
                        </span> -->
                        <!-- <span class="icon">
                            <a href=https://github.com/paschalidoud>
                               <i class="fa fa-github-square fa-2x" aria-hidden="true"></i>
                            </a>
                        </span> -->
                        <!-- <span class="icon">
                            <a href=https://www.linkedin.com/in/paschalidoud>
                                <i class="fa fa-linkedin-square fa-2x" aria-hidden="true"></i>
                            </a>
                        </span> -->
                        <!-- <span class="icon">
                            <a href=https://twitter.com/paschalidoud_1>
                                <i class="fa fa-twitter-square fa-2x" aria-hidden="true"></i>
                            </a>
                        </span> -->
                    </p>
                </div>
            </div>
            <div class="title">
                <span>News</span>
            </div>
            <ul class=news_item>
                <li><span class="news-date">01.02.2021:</span><span class="news-text"> Our paper got accepted at ICASSP 2021.</span></li> 
                <li><span class="news-date">25.11.2020:</span><span class="news-text"> Our paper <a href=https://github.com/korrawe/grasping_field>Grasping Field</a> got best paper award at 3DV2020.</span></li>
                <li><span class="news-date">01.08.2020:</span><span class="news-text"> Started my PhD at ETH Zurich.</span></li>
            </ul>
            <div class="title">
                <span>Publications</span>
            </div>
            <!-- start publication list -->
            <div class="row paper"><div class="image"><img src="teasers/cctc.jpg" alt="Reducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss" /></div><div class="content"><div class="paper-title"><a href="https://arxiv.org/pdf/2005.07920.pdf">Reducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss</a></div><div class="conference">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021</div><div class="authors"> Burin Naowarat, Thananchai Kongthaworn, <strong class="author">Korrawe Karunratanakul</strong>, Sheng Hui Wu, Ekapol Chuangsuwanich </div><div class="links"><a href="#" data-type="Abstract" data-index="0">Abstract</a> <a href="https://arxiv.org/pdf/2005.07920.pdf" data-type="Paper">Paper</a> 
                <!-- <a href="data/fslda_poster.pdf" data-type="Poster">Poster</a> <a href="https://github.com/angeloskath/supervised-lda" data-type="Code">Code</a> <a href="https://mug.ee.auth.gr/discovering-micro-events-video-data-using-topic-modeling/" data-type="Blog">Blog</a> -->
                <a href="#" data-type="Bibtex" data-index="5">Bibtex</a><div class="link-content" data-index="0">Code-Switching (CS) remains a challenge for Automatic Speech Recognition (ASR), especially character-based models. With the combined choice of characters from multiple languages, the outcome from character-based models suffers from phoneme duplication, resulting in language-inconsistent spellings. We propose Contextualized Connectionist Temporal Classification (CCTC) loss to encourage spelling consistencies of a character-based non-autoregressive ASR which allows for faster inference. The CCTC loss conditions the main prediction on the predicted contexts to ensure language consistency in the spellings. In contrast to existing CTC-based approaches, CCTC loss does not require frame-level alignments, since the context ground truth is obtained from the model's estimated path. Compared to the same model trained with regular CTC loss, our method consistently improved the ASR performance on both CS and monolingual corpora.</div><div class="link-content" data-index="5"><pre>@inproceedings{naowarat2020reducing, 
                    title = {Reducing Spelling Inconsistencies in Code-Switching ASR using Contextualized CTC Loss},
                    author = {Naowarat, Burin and Kongthaworn, Thananchai and Karunratanakul, Korrawe and Wu, Sheng Hui and Chuangsuwanich, Ekapol},
                    booktitle = {Proceedings of the 2021 IEEE International Conference on Acoustics, Speech and Signal Processing}, <!-- pages = {332,336}, --> <!-- month = oct, -->
                    year = {2021},
                    <!-- url = {http://dl.acm.org/citation.cfm?id=2967237}, -->
                    <!-- month_numeric = {10} -->
            }</pre></div></div></div></div>
            <div class="row paper"><div class="image"><img src="teasers/grasping_field.jpg" alt="Grasping Field: Learning Implicit Representations for Human Grasps" /></div><div class="content"><div class="paper-title"><a href="https://github.com/korrawe/grasping_field">Grasping Field: Learning Implicit Representations for Human Grasps</a></div><div class="conference">International Conference on 3D Vision (3DV), 2020 (Best Paper Award)</div><div class="authors"><strong class="author">Korrawe Karunratanakul</strong>, Jinlong Yang, Yan Zhang, Michael Black, Krikamol Muandet, Siyu Tang </div><div class="links"><a href="#" data-type="Abstract" data-index="0">Abstract</a> 
                <!-- <a href="https://github.com/korrawe/grasping_field" data-type="Project page">Project page</a>  -->
            <a href="https://arxiv.org/pdf/2008.04451.pdf" data-type="Paper">Paper</a> <a href="https://github.com/korrawe/grasping_field" data-type="Code">Code</a> <a href="#" data-type="Bibtex" data-index="4">Bibtex</a><div class="link-content" data-index="0"> Robotic grasping of house-hold objects has made remarkable progress in recent years. Yet, human grasps are still difficult to synthesize realistically. There are several key reasons: (1) the human hand has many degrees of freedom (more than robotic manipulators); (2) the synthesized hand should conform to the surface of the object; and (3) it should interact with the object in a semantically and physically plausible manner. To make progress in this direction, we draw inspiration from the recent progress on learning-based implicit representations for 3D object reconstruction. Specifically, we propose an expressive representation for human grasp modelling that is efficient and easy to integrate with deep neural networks. Our insight is that every point in a three-dimensional space can be characterized by the signed distances to the surface of the hand and the object, respectively. Consequently, the hand, the object, and the contact area can be represented by implicit surfaces in a common space, in which the proximity between the hand and the object can be modelled explicitly. We name this 3D to 2D mapping as Grasping Field, parameterize it with a deep neural network, and learn it from data. We demonstrate that the proposed grasping field is an effective and expressive representation for human grasp generation. Specifically, our generative model is able to synthesize high-quality human grasps, given only on a 3D object point cloud. The extensive experiments demonstrate that our generative model compares favorably with a strong baseline and approaches the level of natural human grasps. Furthermore, based on the grasping field representation, we propose a deep network for the challenging task of 3D hand-object interaction reconstruction from a single RGB image. Our method improves the physical plausibility of the hand-object contact reconstruction and achieves comparable performance for 3D hand reconstruction compared to state-of-the-art methods.</div><div class="link-content" data-index="4"><pre>@inproceedings{karunratanakul2020grasping,
    title = {Grasping Field: Learning Implicit Representations for Human Grasps},
    author = {Karunratanakul, Korrawe and Yang, Jinlong and Zhang, Yan and Black, Michael and Muandet, Krikamol and Tang, Siyu},
    booktitle = {2020 International Conference on 3D Vision (3DV)},
    month = nov,
    year = {2020}
}</pre></div></div></div></div>
<!-- end publication list -->
        <!-- <div class="title">
            <span>Talks</span>
        </div>
        <div class="row paper">
            <div class="image" style="width:20%">
                <img src="talks/bunny_sq_cr.png" alt="primitive-based-talk" />
            </div>
            <div class="content">
                <div class="presentation-title">
                    <a href="https://paschalidoud.github.io/talks/primitive-based-representations.pdf">Learning Deep Models with Primitive-based Representations</a>
                </div>
                <div class="details">Invited at:
                    <ul>
                        <li>University of Toronto and NVIDIA: 07/10/2020</li>
                        <li><a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas Laboratory</a> @Standford: 17/07/2020</li>
                    </ul>
                </div>
        </div></div></div>
        </div> -->

        <!-- Javascript for showing and hiding the abstract and bibtex -->
        <script type="text/javascript">
            document.querySelectorAll(".links").forEach(function (p) {
                p.addEventListener("click", function (ev) {
                    // Make sure that the click is coming from a link
                    if (ev.target.nodeName != "A") {
                        return;
                    }

                    // Find the index of the div to toggle or return
                    var i = ev.target.dataset["index"];
                    if (i == undefined) {
                        return;
                    }

                    // Make sure to remove something else that was displayed
                    // and toggle the current one
                    Array.prototype.forEach.call(
                        ev.target.parentNode.children,
                        function (sibling) {
                            // We don't care about links etc
                            if (sibling.nodeName != "DIV") {
                                return;
                            }

                            // Hide others
                            if (sibling.dataset["index"] != i) {
                                sibling.style.display = "none";
                            }

                            // toggle the correct one
                            else {
                                if (sibling.style.display != "block") {
                                    sibling.style.display = "block";
                                } else {
                                    sibling.style.display = "none";
                                }
                            }
                        }
                    );
                    ev.preventDefault();
                });
            });
        </script>

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143288088-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-143288088-1');
        </script>
    </body>
</html>
